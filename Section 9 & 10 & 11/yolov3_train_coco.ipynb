{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "yolov3_train_coco.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "38f3ac328813474089bb86dbd6adb029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_89098cfbdb504058b7e04f8078a0f48f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7d38d5ed5aac40749fe7430427de6835",
              "IPY_MODEL_c2a23f3f95eb49448c7e2a8f563505fc",
              "IPY_MODEL_9f9c63fc2a6e4c49aa4e5da1b177c2b1"
            ]
          }
        },
        "89098cfbdb504058b7e04f8078a0f48f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d38d5ed5aac40749fe7430427de6835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2bf77efcac5040e6b55a67d425cf27e2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3452b0046e014ca9a1d8dd23495e5869"
          }
        },
        "c2a23f3f95eb49448c7e2a8f563505fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c52f61498bd94343a102e06ab40b8d82",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 6984509,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6984509,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_deea9af6b2a648aabb1facf4e7b29ee8"
          }
        },
        "9f9c63fc2a6e4c49aa4e5da1b177c2b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dc9b2df1dfb949e18b72485f44976c72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6.66M/6.66M [00:00&lt;00:00, 15.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3dc8a8b29614f28916f9f6ae360a03c"
          }
        },
        "2bf77efcac5040e6b55a67d425cf27e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3452b0046e014ca9a1d8dd23495e5869": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c52f61498bd94343a102e06ab40b8d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "deea9af6b2a648aabb1facf4e7b29ee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc9b2df1dfb949e18b72485f44976c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3dc8a8b29614f28916f9f6ae360a03c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPvjfCWE2KFj"
      },
      "source": [
        "### Ultralytics Yolo v3 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "I_Ua0GO8Sa5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4904572f-dde1-4038-b655-0e8a19cc78a3"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov3\n",
        "!cd yolov3;pip install -qr requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov3'...\n",
            "remote: Enumerating objects: 9862, done.\u001b[K\n",
            "remote: Total 9862 (delta 0), reused 0 (delta 0), pack-reused 9862\u001b[K\n",
            "Receiving objects: 100% (9862/9862), 9.19 MiB | 20.87 MiB/s, done.\n",
            "Resolving deltas: 100% (6667/6667), done.\n",
            "\u001b[K     |████████████████████████████████| 596 kB 5.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b1xaZlnSSa53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abd54b3e-5ba3-49f6-e039-966e24b7030b"
      },
      "source": [
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.9.0+cu111 (Tesla K80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wuNsf3fL2kD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "880f90ef-a849-4e19-dc2e-80e496bb46cc"
      },
      "source": [
        "%cd yolov3\n",
        "!python train.py --img 640 --batch 8 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov3\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.5.0-13-g1be3170 torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=8, bbox_interval=-1, bucket='', cache_images=False, cfg='', data='./data/coco128.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=8, upload_dataset=False, weights='yolov3.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv3 logging with 'pip install wandb' (recommended)\n",
            "Downloading https://github.com/ultralytics/yolov3/releases/download/v9.5.0/yolov3.pt to yolov3.pt...\n",
            "100% 118M/118M [00:01<00:00, 92.3MB/s]\n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.4 GFLOPS\n",
            "\n",
            "Transferred 440/440 items from yolov3.pt\n",
            "\n",
            "WARNING: Dataset not found, nonexistent paths: ['/content/coco128/images/train2017']\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip ...\n",
            "100% 6.66M/6.66M [00:00<00:00, 75.1MB/s]\n",
            "Dataset autodownload success\n",
            "\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 75 .bias, 75 conv.weight, 72 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../coco128/labels/train2017' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 605.33it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.26, Best Possible Recall (BPR) = 0.9946\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/2     7.31G   0.02774   0.02394  0.007242   0.05893       111       640:   0% 0/16 [00:10<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:730: UserWarning: The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\n",
            "  \"The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\"\n",
            "       0/2     9.67G   0.02976   0.02503  0.008362   0.06316        68       640: 100% 16/16 [00:59<00:00,  3.71s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:25<00:00,  3.24s/it]\n",
            "                 all         128         929       0.816       0.652       0.788       0.541\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/2     9.51G   0.03084   0.02501  0.008129   0.06398        86       640: 100% 16/16 [00:31<00:00,  1.96s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:07<00:00,  1.08it/s]\n",
            "                 all         128         929       0.796       0.671       0.789       0.541\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/2     9.51G   0.02896   0.02226   0.01129    0.0625       121       640: 100% 16/16 [00:31<00:00,  1.96s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:08<00:00,  1.09s/it]\n",
            "                 all         128         929       0.804       0.674       0.796       0.542\n",
            "3 epochs completed in 0.049 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 124.2MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 124.2MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtQd5TmHMgxE"
      },
      "source": [
        "### wandb(weight and bias) 모듈을 설치\n",
        "* 먼저 Weight and Bias 웹사이트에 계정 생성 및 연계 후 train 작업이 필요할 수도 있음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKc9lL_oKCPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d916b4-4ead-4a3e-d6dd-fb6d34f6b1e5"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.6-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 45.7 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.4.3-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 46.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=f6341322069f20b63f6653c05a49a16d1814c2c3b2e9d8aee6f68e1d764c8c2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=cdefe53b3351e8fb58cae65d39de5f392020edfcfa1ed2b9146fc92ea6a8be98\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
            "Successfully installed GitPython-3.1.24 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.4.3 shortuuid-1.0.1 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.6 yaspin-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T2Hcsh1R5iB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55ab14ec-cf0b-49e0-b0f6-ab63e6063aab"
      },
      "source": [
        "%cd /content\n",
        "%cd yolov3\n",
        "!python train.py --img 640 --batch 8 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/yolov3\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.5.0-13-g1be3170 torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=8, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='./data/coco128.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp4', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=8, upload_dataset=False, weights='yolov3.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Don't visualize my results'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 21mb73c1.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to `offline` in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.4 GFLOPS\n",
            "\n",
            "Transferred 440/440 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 75 .bias, 75 conv.weight, 72 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 254.79it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 151.22it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.26, Best Possible Recall (BPR) = 0.9946\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp4\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/2     7.31G   0.02774   0.02394  0.007242   0.05893       111       640:   0% 0/16 [00:09<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:730: UserWarning: The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\n",
            "  \"The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\"\n",
            "       0/2     9.67G   0.02976   0.02503  0.008362   0.06316        68       640: 100% 16/16 [00:57<00:00,  3.59s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:26<00:00,  3.36s/it]\n",
            "                 all         128         929       0.814       0.654       0.788       0.541\n",
            "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/2     9.51G   0.03084   0.02501  0.008129   0.06398        86       640: 100% 16/16 [00:31<00:00,  1.95s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:08<00:00,  1.10s/it]\n",
            "                 all         128         929       0.796       0.671        0.79       0.541\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/2     9.51G   0.02896   0.02225   0.01129    0.0625       121       640: 100% 16/16 [00:30<00:00,  1.93s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:10<00:00,  1.27s/it]\n",
            "                 all         128         929       0.805       0.673       0.796       0.545\n",
            "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
            "3 epochs completed in 0.049 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp4/weights/last.pt, 124.2MB\n",
            "Optimizer stripped from runs/train/exp4/weights/best.pt, 124.2MB\n",
            "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 574... (success).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 ▁▃█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 ▁▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision █▁▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall ▁▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss ▄█▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss ▂▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss ██▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss █▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss █▄▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss █▃▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 ▁█▄\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 ▁█▄\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 █▅▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 0.79605\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 0.54536\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision 0.80528\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall 0.67314\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss 0.02896\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss 0.01129\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss 0.02225\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss 0.02852\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss 0.00453\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss 0.01516\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 0.00019\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 0.00019\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 0.09549\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mwandb sync /content/yolov3/wandb/offline-run-20211031_051031-21mb73c1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[0mFind logs at: ./wandb/offline-run-20211031_051031-21mb73c1/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNIrsZHI0_tz"
      },
      "source": [
        "### Dataset Config와 Weight 파일의 상대 경로, 절대 경로\n",
        "* train.py의 data option값으로 Dataset config yaml 파일을 지정할 수 있으며, 파일명만 입력할 경우는 yolov3/data 디렉토리 아래에서 해당 파일을 찾음. 절대 경로로 입력할 경우 해당 경로에서 찾음. \n",
        "* weights option의 경우 파일명만 입력할 경우 yolov3 디렉토리에서 해당 파일을 찾음. 해당 파일이 없을 경우 자동으로 해당 파일을 https://github.com/ultralytics/yolov3/releases 에서 Download 함. 절대 경로를 입력한 경우 해당 경로에서 파일을 찾되 파일이 없으면 해당 경로로 자동 Download함. \n",
        "* weights 파일은 yolov3.pt, yolov3-tiny.pt, yolov3-spp.pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLfxF4g_3Zh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8314a2-bb58-4a8d-dc15-19a543ee247d"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wPnWKNXMSa5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63ec5cc6-f63d-4990-8a2a-f68e11a83ef5"
      },
      "source": [
        "!cd yolov3; python train.py --img 640 --batch 8 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave --cache\n",
        "#!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights '' --cfg yolov3.yaml --nosave --cache # weight가 공란이면 반드시 cfg 라고 써주어야 함!!\n",
        "#!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3-tiny.pt --nosave --cache\n",
        "#!cd yolov3;python train.py --img 640 --batch 16 --epochs 3 --data /content/coco128/coco128.yaml --weights /content/coco128/yolov3-tiny.pt --nosave --cache\n",
        "#!cd yolov3;python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3-spp.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.5.0-13-g1be3170 torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=8, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='./data/coco128.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=8, upload_dataset=False, weights='yolov3.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv3 logging with 'pip install wandb' (recommended)\n",
            "Downloading https://github.com/ultralytics/yolov3/releases/download/v9.5.0/yolov3.pt to yolov3.pt...\n",
            "100% 118M/118M [00:01<00:00, 103MB/s] \n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.4 GFLOPS\n",
            "\n",
            "Transferred 440/440 items from yolov3.pt\n",
            "\n",
            "WARNING: Dataset not found, nonexistent paths: ['/content/coco128/images/train2017']\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip ...\n",
            "100% 6.66M/6.66M [00:00<00:00, 65.7MB/s]\n",
            "Dataset autodownload success\n",
            "\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 75 .bias, 75 conv.weight, 72 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../coco128/labels/train2017' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 672.83it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 252.71it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 166.42it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.26, Best Possible Recall (BPR) = 0.9946\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/2     7.31G   0.02774   0.02394  0.007242   0.05893       111       640:   0% 0/16 [00:11<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:730: UserWarning: The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\n",
            "  \"The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\"\n",
            "       0/2     9.67G   0.02976   0.02503  0.008362   0.06316        68       640: 100% 16/16 [01:02<00:00,  3.89s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:28<00:00,  3.51s/it]\n",
            "                 all         128         929       0.802       0.662       0.787       0.542\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/2     9.51G   0.03084   0.02501   0.00813   0.06398        86       640: 100% 16/16 [00:33<00:00,  2.08s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:07<00:00,  1.02it/s]\n",
            "                 all         128         929       0.797       0.672        0.79       0.541\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/2     9.51G   0.02896   0.02226   0.01129    0.0625       121       640: 100% 16/16 [00:33<00:00,  2.07s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:09<00:00,  1.15s/it]\n",
            "                 all         128         929       0.805       0.673       0.796       0.541\n",
            "3 epochs completed in 0.051 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 124.2MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aumMX7EOnbi",
        "outputId": "8de6c306-f0e3-4f4a-ff2f-4b5b2dd1ee78"
      },
      "source": [
        "#!cd yolov3; python train.py --img 640 --batch 8 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave --cache\n",
        "#!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights '' --cfg yolov3.yaml --nosave --cache # weight가 공란이면 반드시 cfg 라고 써주어야 함!!\n",
        "!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3-tiny.pt --nosave --cache\n",
        "#!cd yolov3;python train.py --img 640 --batch 16 --epochs 3 --data /content/coco128/coco128.yaml --weights /content/coco128/yolov3-tiny.pt --nosave --cache\n",
        "#!cd yolov3;python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3-spp.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.5.0-13-g1be3170 torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='./data/coco128.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp2', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, weights='yolov3-tiny.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv3 logging with 'pip install wandb' (recommended)\n",
            "Downloading https://github.com/ultralytics/yolov3/releases/download/v9.5.0/yolov3-tiny.pt to yolov3-tiny.pt...\n",
            "100% 16.9M/16.9M [00:00<00:00, 101MB/s] \n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       464  models.common.Conv                      [3, 16, 3, 1]                 \n",
            "  1                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  2                -1  1      4672  models.common.Conv                      [16, 32, 3, 1]                \n",
            "  3                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  4                -1  1     18560  models.common.Conv                      [32, 64, 3, 1]                \n",
            "  5                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  6                -1  1     73984  models.common.Conv                      [64, 128, 3, 1]               \n",
            "  7                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  8                -1  1    295424  models.common.Conv                      [128, 256, 3, 1]              \n",
            "  9                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            " 10                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.padding.ZeroPad2d      [[0, 1, 0, 1]]                \n",
            " 12                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 1, 0]                     \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 15                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 16                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1    885248  models.common.Conv                      [384, 256, 3, 1]              \n",
            " 20          [19, 15]  1    196350  models.yolo.Detect                      [80, [[10, 14, 23, 27, 37, 58], [81, 82, 135, 169, 344, 319]], [256, 512]]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Model Summary: 59 layers, 8852366 parameters, 8852366 gradients, 13.3 GFLOPS\n",
            "\n",
            "Transferred 72/72 items from yolov3-tiny.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 13 .bias, 13 conv.weight, 11 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 264.67it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 198.72it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.85, Best Possible Recall (BPR) = 0.9903\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp2\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/2     2.75G   0.05195   0.07895   0.02406     0.155       184       640:   0% 0/8 [00:07<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:730: UserWarning: The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\n",
            "  \"The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\"\n",
            "       0/2     7.33G   0.05314    0.0958   0.02647    0.1754       199       640: 100% 8/8 [00:14<00:00,  1.85s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:15<00:00,  3.87s/it]\n",
            "                 all         128         929       0.551       0.358       0.427        0.22\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/2     6.32G   0.05206   0.08904   0.02672    0.1678       130       640: 100% 8/8 [00:03<00:00,  2.43it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:01<00:00,  2.20it/s]\n",
            "                 all         128         929       0.552        0.36       0.425       0.223\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/2     6.32G   0.05491   0.09181   0.02641    0.1731       163       640: 100% 8/8 [00:03<00:00,  2.46it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.06it/s]\n",
            "                 all         128         929       0.565       0.366        0.43       0.225\n",
            "3 epochs completed in 0.014 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp2/weights/last.pt, 17.8MB\n",
            "Optimizer stripped from runs/train/exp2/weights/best.pt, 17.8MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn1UHmyLPAZ5",
        "outputId": "7c10fb1d-7575-4992-ba63-e01eafed09dd"
      },
      "source": [
        "!cd yolov3;python train.py --img 640 --batch 16 --epochs 3 --data /content/coco128/coco128.yaml --weights /content/coco128/yolov3-tiny.pt --nosave --cache\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.5.0-13-g1be3170 torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='/content/coco128/coco128.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp3', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, weights='/content/coco128/yolov3-tiny.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv3 logging with 'pip install wandb' (recommended)\n",
            "Downloading https://github.com/ultralytics/yolov3/releases/download/v9.5.0/yolov3-tiny.pt to /content/coco128/yolov3-tiny.pt...\n",
            "100% 16.9M/16.9M [00:00<00:00, 98.9MB/s]\n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       464  models.common.Conv                      [3, 16, 3, 1]                 \n",
            "  1                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  2                -1  1      4672  models.common.Conv                      [16, 32, 3, 1]                \n",
            "  3                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  4                -1  1     18560  models.common.Conv                      [32, 64, 3, 1]                \n",
            "  5                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  6                -1  1     73984  models.common.Conv                      [64, 128, 3, 1]               \n",
            "  7                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  8                -1  1    295424  models.common.Conv                      [128, 256, 3, 1]              \n",
            "  9                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            " 10                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.padding.ZeroPad2d      [[0, 1, 0, 1]]                \n",
            " 12                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 1, 0]                     \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 15                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 16                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1    885248  models.common.Conv                      [384, 256, 3, 1]              \n",
            " 20          [19, 15]  1    196350  models.yolo.Detect                      [80, [[10, 14, 23, 27, 37, 58], [81, 82, 135, 169, 344, 319]], [256, 512]]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Model Summary: 59 layers, 8852366 parameters, 8852366 gradients, 13.3 GFLOPS\n",
            "\n",
            "Transferred 72/72 items from /content/coco128/yolov3-tiny.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 13 .bias, 13 conv.weight, 11 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 274.63it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 203.68it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.85, Best Possible Recall (BPR) = 0.9903\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp3\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/2     2.75G   0.05195   0.07895   0.02406     0.155       184       640:   0% 0/8 [00:07<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:730: UserWarning: The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\n",
            "  \"The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\"\n",
            "       0/2     7.33G   0.05314    0.0958   0.02647    0.1754       199       640: 100% 8/8 [00:14<00:00,  1.83s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:15<00:00,  3.91s/it]\n",
            "                 all         128         929        0.55       0.357       0.427       0.221\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/2     6.32G   0.05206   0.08904   0.02672    0.1678       130       640: 100% 8/8 [00:03<00:00,  2.44it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:01<00:00,  2.21it/s]\n",
            "                 all         128         929       0.552        0.36       0.424       0.223\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/2     6.32G   0.05491   0.09181   0.02641    0.1731       163       640: 100% 8/8 [00:03<00:00,  2.47it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.06it/s]\n",
            "                 all         128         929       0.567       0.365        0.43       0.225\n",
            "3 epochs completed in 0.014 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp3/weights/last.pt, 17.8MB\n",
            "Optimizer stripped from runs/train/exp3/weights/best.pt, 17.8MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZSXORZdEmvc"
      },
      "source": [
        "!cp /content/yolov3/data/coco128.yaml /content/coco128/coco128.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf1hUSV6Myw9"
      },
      "source": [
        "### COCO128 데이터 디렉토리를 변경후 학습 수행\n",
        "* /content/data 아래에 coco128 데이터 download 후 unzip\n",
        "* coco128 디렉토리가 변경되었으므로 **coco128.yaml 데이터도 변경 적용.** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz37RavwxYE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b84daef-e3f9-4d36-a938-033cd74967e1"
      },
      "source": [
        "%cd /content\n",
        "!rm -rf /content/coco128 # coco128 폴더 삭제"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "guG3eNgXSa56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "38f3ac328813474089bb86dbd6adb029",
            "89098cfbdb504058b7e04f8078a0f48f",
            "7d38d5ed5aac40749fe7430427de6835",
            "c2a23f3f95eb49448c7e2a8f563505fc",
            "9f9c63fc2a6e4c49aa4e5da1b177c2b1",
            "2bf77efcac5040e6b55a67d425cf27e2",
            "3452b0046e014ca9a1d8dd23495e5869",
            "c52f61498bd94343a102e06ab40b8d82",
            "deea9af6b2a648aabb1facf4e7b29ee8",
            "dc9b2df1dfb949e18b72485f44976c72",
            "d3dc8a8b29614f28916f9f6ae360a03c"
          ]
        },
        "outputId": "64919bab-c047-44ca-eeb9-63c33676c5af"
      },
      "source": [
        "# /content 디렉토리에 coco128.zip을 download하고 tmp.zip으로 이름 변경 후 압축 해제. \n",
        "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip', 'tmp.zip')\n",
        "!unzip -q tmp.zip -d ./ && rm tmp.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38f3ac328813474089bb86dbd6adb029",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/6.66M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD-azX0i2m-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d68554-a73c-44a5-fe0d-815dda853e6a"
      },
      "source": [
        "# /content/data 디렉토리에 coco128.zip을 download하고 압축 해제\n",
        "!mkdir /content/data\n",
        "!wget -O /content/data/coco128.zip https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip\n",
        "!cd /content/data; unzip coco128.zip "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-31 07:30:44--  https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/264818686/7a208a00-e19d-11eb-94cf-5222600cc665?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211031%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211031T073044Z&X-Amz-Expires=300&X-Amz-Signature=f7b80dd9b0e5c205aa9bd0a8cfa5f488de548d0a2edab49d26c7d06af03db153&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dcoco128.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-10-31 07:30:44--  https://github-releases.githubusercontent.com/264818686/7a208a00-e19d-11eb-94cf-5222600cc665?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211031%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211031T073044Z&X-Amz-Expires=300&X-Amz-Signature=f7b80dd9b0e5c205aa9bd0a8cfa5f488de548d0a2edab49d26c7d06af03db153&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dcoco128.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.109.154, 185.199.111.154, 185.199.108.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.109.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6984509 (6.7M) [application/octet-stream]\n",
            "Saving to: ‘/content/data/coco128.zip’\n",
            "\n",
            "/content/data/coco1 100%[===================>]   6.66M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2021-10-31 07:30:45 (76.3 MB/s) - ‘/content/data/coco128.zip’ saved [6984509/6984509]\n",
            "\n",
            "Archive:  coco128.zip\n",
            "   creating: coco128/\n",
            "  inflating: coco128/.DS_Store       \n",
            "  inflating: coco128/LICENSE         \n",
            "   creating: coco128/images/\n",
            "  inflating: coco128/images/.DS_Store  \n",
            "   creating: coco128/images/train2017/\n",
            "  inflating: coco128/images/train2017/000000000612.jpg  \n",
            "  inflating: coco128/images/train2017/000000000404.jpg  \n",
            "  inflating: coco128/images/train2017/000000000438.jpg  \n",
            "  inflating: coco128/images/train2017/000000000389.jpg  \n",
            "  inflating: coco128/images/train2017/000000000564.jpg  \n",
            "  inflating: coco128/images/train2017/000000000149.jpg  \n",
            "  inflating: coco128/images/train2017/000000000605.jpg  \n",
            "  inflating: coco128/images/train2017/000000000349.jpg  \n",
            "  inflating: coco128/images/train2017/000000000201.jpg  \n",
            "  inflating: coco128/images/train2017/000000000599.jpg  \n",
            "  inflating: coco128/images/train2017/000000000572.jpg  \n",
            "  inflating: coco128/images/train2017/000000000360.jpg  \n",
            "  inflating: coco128/images/train2017/000000000370.jpg  \n",
            "  inflating: coco128/images/train2017/000000000562.jpg  \n",
            "  inflating: coco128/images/train2017/000000000589.jpg  \n",
            "  inflating: coco128/images/train2017/.DS_Store  \n",
            "  inflating: coco128/images/train2017/000000000359.jpg  \n",
            "  inflating: coco128/images/train2017/000000000629.jpg  \n",
            "  inflating: coco128/images/train2017/000000000165.jpg  \n",
            "  inflating: coco128/images/train2017/000000000415.jpg  \n",
            "  inflating: coco128/images/train2017/000000000575.jpg  \n",
            "  inflating: coco128/images/train2017/000000000560.jpg  \n",
            "  inflating: coco128/images/train2017/000000000400.jpg  \n",
            "  inflating: coco128/images/train2017/000000000428.jpg  \n",
            "  inflating: coco128/images/train2017/000000000164.jpg  \n",
            "  inflating: coco128/images/train2017/000000000315.jpg  \n",
            "  inflating: coco128/images/train2017/000000000077.jpg  \n",
            "  inflating: coco128/images/train2017/000000000089.jpg  \n",
            "  inflating: coco128/images/train2017/000000000260.jpg  \n",
            "  inflating: coco128/images/train2017/000000000328.jpg  \n",
            "  inflating: coco128/images/train2017/000000000472.jpg  \n",
            "  inflating: coco128/images/train2017/000000000510.jpg  \n",
            "  inflating: coco128/images/train2017/000000000074.jpg  \n",
            "  inflating: coco128/images/train2017/000000000049.jpg  \n",
            "  inflating: coco128/images/train2017/000000000061.jpg  \n",
            "  inflating: coco128/images/train2017/000000000263.jpg  \n",
            "  inflating: coco128/images/train2017/000000000459.jpg  \n",
            "  inflating: coco128/images/train2017/000000000471.jpg  \n",
            "  inflating: coco128/images/train2017/000000000307.jpg  \n",
            "  inflating: coco128/images/train2017/000000000529.jpg  \n",
            "  inflating: coco128/images/train2017/000000000071.jpg  \n",
            "  inflating: coco128/images/train2017/000000000064.jpg  \n",
            "  inflating: coco128/images/train2017/000000000514.jpg  \n",
            "  inflating: coco128/images/train2017/000000000474.jpg  \n",
            "  inflating: coco128/images/train2017/000000000312.jpg  \n",
            "  inflating: coco128/images/train2017/000000000110.jpg  \n",
            "  inflating: coco128/images/train2017/000000000138.jpg  \n",
            "  inflating: coco128/images/train2017/000000000338.jpg  \n",
            "  inflating: coco128/images/train2017/000000000502.jpg  \n",
            "  inflating: coco128/images/train2017/000000000072.jpg  \n",
            "  inflating: coco128/images/train2017/000000000073.jpg  \n",
            "  inflating: coco128/images/train2017/000000000488.jpg  \n",
            "  inflating: coco128/images/train2017/000000000113.jpg  \n",
            "  inflating: coco128/images/train2017/000000000136.jpg  \n",
            "  inflating: coco128/images/train2017/000000000650.jpg  \n",
            "  inflating: coco128/images/train2017/000000000446.jpg  \n",
            "  inflating: coco128/images/train2017/000000000308.jpg  \n",
            "  inflating: coco128/images/train2017/000000000491.jpg  \n",
            "  inflating: coco128/images/train2017/000000000532.jpg  \n",
            "  inflating: coco128/images/train2017/000000000283.jpg  \n",
            "  inflating: coco128/images/train2017/000000000042.jpg  \n",
            "  inflating: coco128/images/train2017/000000000081.jpg  \n",
            "  inflating: coco128/images/train2017/000000000094.jpg  \n",
            "  inflating: coco128/images/train2017/000000000241.jpg  \n",
            "  inflating: coco128/images/train2017/000000000490.jpg  \n",
            "  inflating: coco128/images/train2017/000000000309.jpg  \n",
            "  inflating: coco128/images/train2017/000000000321.jpg  \n",
            "  inflating: coco128/images/train2017/000000000109.jpg  \n",
            "  inflating: coco128/images/train2017/000000000486.jpg  \n",
            "  inflating: coco128/images/train2017/000000000531.jpg  \n",
            "  inflating: coco128/images/train2017/000000000257.jpg  \n",
            "  inflating: coco128/images/train2017/000000000294.jpg  \n",
            "  inflating: coco128/images/train2017/000000000450.jpg  \n",
            "  inflating: coco128/images/train2017/000000000322.jpg  \n",
            "  inflating: coco128/images/train2017/000000000326.jpg  \n",
            "  inflating: coco128/images/train2017/000000000332.jpg  \n",
            "  inflating: coco128/images/train2017/000000000508.jpg  \n",
            "  inflating: coco128/images/train2017/000000000520.jpg  \n",
            "  inflating: coco128/images/train2017/000000000078.jpg  \n",
            "  inflating: coco128/images/train2017/000000000086.jpg  \n",
            "  inflating: coco128/images/train2017/000000000092.jpg  \n",
            "  inflating: coco128/images/train2017/000000000247.jpg  \n",
            "  inflating: coco128/images/train2017/000000000643.jpg  \n",
            "  inflating: coco128/images/train2017/000000000133.jpg  \n",
            "  inflating: coco128/images/train2017/000000000127.jpg  \n",
            "  inflating: coco128/images/train2017/000000000641.jpg  \n",
            "  inflating: coco128/images/train2017/000000000443.jpg  \n",
            "  inflating: coco128/images/train2017/000000000536.jpg  \n",
            "  inflating: coco128/images/train2017/000000000250.jpg  \n",
            "  inflating: coco128/images/train2017/000000000196.jpg  \n",
            "  inflating: coco128/images/train2017/000000000357.jpg  \n",
            "  inflating: coco128/images/train2017/000000000431.jpg  \n",
            "  inflating: coco128/images/train2017/000000000419.jpg  \n",
            "  inflating: coco128/images/train2017/000000000394.jpg  \n",
            "  inflating: coco128/images/train2017/000000000009.jpg  \n",
            "  inflating: coco128/images/train2017/000000000034.jpg  \n",
            "  inflating: coco128/images/train2017/000000000544.jpg  \n",
            "  inflating: coco128/images/train2017/000000000395.jpg  \n",
            "  inflating: coco128/images/train2017/000000000626.jpg  \n",
            "  inflating: coco128/images/train2017/000000000154.jpg  \n",
            "  inflating: coco128/images/train2017/000000000142.jpg  \n",
            "  inflating: coco128/images/train2017/000000000368.jpg  \n",
            "  inflating: coco128/images/train2017/000000000397.jpg  \n",
            "  inflating: coco128/images/train2017/000000000208.jpg  \n",
            "  inflating: coco128/images/train2017/000000000036.jpg  \n",
            "  inflating: coco128/images/train2017/000000000584.jpg  \n",
            "  inflating: coco128/images/train2017/000000000590.jpg  \n",
            "  inflating: coco128/images/train2017/000000000382.jpg  \n",
            "  inflating: coco128/images/train2017/000000000194.jpg  \n",
            "  inflating: coco128/images/train2017/000000000625.jpg  \n",
            "  inflating: coco128/images/train2017/000000000143.jpg  \n",
            "  inflating: coco128/images/train2017/000000000581.jpg  \n",
            "  inflating: coco128/images/train2017/000000000595.jpg  \n",
            "  inflating: coco128/images/train2017/000000000542.jpg  \n",
            "  inflating: coco128/images/train2017/000000000387.jpg  \n",
            "  inflating: coco128/images/train2017/000000000436.jpg  \n",
            "  inflating: coco128/images/train2017/000000000634.jpg  \n",
            "  inflating: coco128/images/train2017/000000000620.jpg  \n",
            "  inflating: coco128/images/train2017/000000000636.jpg  \n",
            "  inflating: coco128/images/train2017/000000000144.jpg  \n",
            "  inflating: coco128/images/train2017/000000000540.jpg  \n",
            "  inflating: coco128/images/train2017/000000000597.jpg  \n",
            "  inflating: coco128/images/train2017/000000000030.jpg  \n",
            "  inflating: coco128/images/train2017/000000000025.jpg  \n",
            "  inflating: coco128/images/train2017/000000000569.jpg  \n",
            "  inflating: coco128/images/train2017/000000000384.jpg  \n",
            "  inflating: coco128/images/train2017/000000000192.jpg  \n",
            "  inflating: coco128/images/train2017/000000000623.jpg  \n",
            "  inflating: coco128/images/train2017/000000000151.jpg  \n",
            "   creating: coco128/labels/\n",
            "  inflating: coco128/labels/.DS_Store  \n",
            "   creating: coco128/labels/train2017/\n",
            "  inflating: coco128/labels/train2017/000000000260.txt  \n",
            "  inflating: coco128/labels/train2017/000000000089.txt  \n",
            "  inflating: coco128/labels/train2017/000000000328.txt  \n",
            "  inflating: coco128/labels/train2017/000000000472.txt  \n",
            "  inflating: coco128/labels/train2017/000000000315.txt  \n",
            "  inflating: coco128/labels/train2017/000000000077.txt  \n",
            "  inflating: coco128/labels/train2017/000000000263.txt  \n",
            "  inflating: coco128/labels/train2017/000000000049.txt  \n",
            "  inflating: coco128/labels/train2017/000000000061.txt  \n",
            "  inflating: coco128/labels/train2017/000000000459.txt  \n",
            "  inflating: coco128/labels/train2017/000000000471.txt  \n",
            "  inflating: coco128/labels/train2017/000000000074.txt  \n",
            "  inflating: coco128/labels/train2017/000000000510.txt  \n",
            "  inflating: coco128/labels/train2017/000000000514.txt  \n",
            "  inflating: coco128/labels/train2017/000000000064.txt  \n",
            "  inflating: coco128/labels/train2017/000000000110.txt  \n",
            "  inflating: coco128/labels/train2017/000000000138.txt  \n",
            "  inflating: coco128/labels/train2017/000000000312.txt  \n",
            "  inflating: coco128/labels/train2017/000000000474.txt  \n",
            "  inflating: coco128/labels/train2017/000000000307.txt  \n",
            "  inflating: coco128/labels/train2017/000000000071.txt  \n",
            "  inflating: coco128/labels/train2017/000000000529.txt  \n",
            "  inflating: coco128/labels/train2017/000000000073.txt  \n",
            "  inflating: coco128/labels/train2017/000000000113.txt  \n",
            "  inflating: coco128/labels/train2017/000000000488.txt  \n",
            "  inflating: coco128/labels/train2017/000000000338.txt  \n",
            "  inflating: coco128/labels/train2017/000000000072.txt  \n",
            "  inflating: coco128/labels/train2017/000000000502.txt  \n",
            "  inflating: coco128/labels/train2017/000000000149.txt  \n",
            "  inflating: coco128/labels/train2017/000000000389.txt  \n",
            "  inflating: coco128/labels/train2017/000000000404.txt  \n",
            "  inflating: coco128/labels/train2017/000000000438.txt  \n",
            "  inflating: coco128/labels/train2017/000000000612.txt  \n",
            "  inflating: coco128/labels/train2017/000000000564.txt  \n",
            "  inflating: coco128/labels/train2017/000000000572.txt  \n",
            "  inflating: coco128/labels/train2017/000000000599.txt  \n",
            "  inflating: coco128/labels/train2017/000000000360.txt  \n",
            "  inflating: coco128/labels/train2017/000000000349.txt  \n",
            "  inflating: coco128/labels/train2017/000000000605.txt  \n",
            "  inflating: coco128/labels/train2017/000000000201.txt  \n",
            "  inflating: coco128/labels/train2017/000000000629.txt  \n",
            "  inflating: coco128/labels/train2017/000000000359.txt  \n",
            "  inflating: coco128/labels/train2017/000000000370.txt  \n",
            "  inflating: coco128/labels/train2017/000000000589.txt  \n",
            "  inflating: coco128/labels/train2017/000000000562.txt  \n",
            "  inflating: coco128/labels/train2017/000000000560.txt  \n",
            "  inflating: coco128/labels/train2017/000000000164.txt  \n",
            "  inflating: coco128/labels/train2017/000000000400.txt  \n",
            "  inflating: coco128/labels/train2017/000000000428.txt  \n",
            "  inflating: coco128/labels/train2017/000000000415.txt  \n",
            "  inflating: coco128/labels/train2017/000000000165.txt  \n",
            "  inflating: coco128/labels/train2017/000000000575.txt  \n",
            "  inflating: coco128/labels/train2017/000000000544.txt  \n",
            "  inflating: coco128/labels/train2017/000000000034.txt  \n",
            "  inflating: coco128/labels/train2017/000000000626.txt  \n",
            "  inflating: coco128/labels/train2017/000000000154.txt  \n",
            "  inflating: coco128/labels/train2017/000000000395.txt  \n",
            "  inflating: coco128/labels/train2017/000000000394.txt  \n",
            "  inflating: coco128/labels/train2017/000000000431.txt  \n",
            "  inflating: coco128/labels/train2017/000000000357.txt  \n",
            "  inflating: coco128/labels/train2017/000000000419.txt  \n",
            "  inflating: coco128/labels/train2017/000000000196.txt  \n",
            "  inflating: coco128/labels/train2017/000000000009.txt  \n",
            "  inflating: coco128/labels/train2017/000000000584.txt  \n",
            "  inflating: coco128/labels/train2017/000000000590.txt  \n",
            "  inflating: coco128/labels/train2017/000000000143.txt  \n",
            "  inflating: coco128/labels/train2017/000000000625.txt  \n",
            "  inflating: coco128/labels/train2017/000000000194.txt  \n",
            "  inflating: coco128/labels/train2017/000000000382.txt  \n",
            "  inflating: coco128/labels/train2017/000000000397.txt  \n",
            "  inflating: coco128/labels/train2017/000000000368.txt  \n",
            "  inflating: coco128/labels/train2017/000000000142.txt  \n",
            "  inflating: coco128/labels/train2017/000000000036.txt  \n",
            "  inflating: coco128/labels/train2017/000000000208.txt  \n",
            "  inflating: coco128/labels/train2017/000000000542.txt  \n",
            "  inflating: coco128/labels/train2017/000000000581.txt  \n",
            "  inflating: coco128/labels/train2017/000000000595.txt  \n",
            "  inflating: coco128/labels/train2017/000000000634.txt  \n",
            "  inflating: coco128/labels/train2017/000000000620.txt  \n",
            "  inflating: coco128/labels/train2017/000000000436.txt  \n",
            "  inflating: coco128/labels/train2017/000000000387.txt  \n",
            "  inflating: coco128/labels/train2017/000000000569.txt  \n",
            "  inflating: coco128/labels/train2017/000000000025.txt  \n",
            "  inflating: coco128/labels/train2017/000000000623.txt  \n",
            "  inflating: coco128/labels/train2017/000000000151.txt  \n",
            "  inflating: coco128/labels/train2017/000000000192.txt  \n",
            "  inflating: coco128/labels/train2017/000000000384.txt  \n",
            "  inflating: coco128/labels/train2017/000000000636.txt  \n",
            "  inflating: coco128/labels/train2017/000000000144.txt  \n",
            "  inflating: coco128/labels/train2017/000000000030.txt  \n",
            "  inflating: coco128/labels/train2017/000000000597.txt  \n",
            "  inflating: coco128/labels/train2017/000000000540.txt  \n",
            "  inflating: coco128/labels/train2017/000000000241.txt  \n",
            "  inflating: coco128/labels/train2017/000000000094.txt  \n",
            "  inflating: coco128/labels/train2017/000000000309.txt  \n",
            "  inflating: coco128/labels/train2017/000000000321.txt  \n",
            "  inflating: coco128/labels/train2017/000000000490.txt  \n",
            "  inflating: coco128/labels/train2017/000000000491.txt  \n",
            "  inflating: coco128/labels/train2017/000000000446.txt  \n",
            "  inflating: coco128/labels/train2017/000000000308.txt  \n",
            "  inflating: coco128/labels/train2017/000000000650.txt  \n",
            "  inflating: coco128/labels/train2017/000000000136.txt  \n",
            "  inflating: coco128/labels/train2017/000000000081.txt  \n",
            "  inflating: coco128/labels/train2017/000000000042.txt  \n",
            "  inflating: coco128/labels/train2017/000000000283.txt  \n",
            "  inflating: coco128/labels/train2017/000000000532.txt  \n",
            "  inflating: coco128/labels/train2017/000000000450.txt  \n",
            "  inflating: coco128/labels/train2017/000000000322.txt  \n",
            "  inflating: coco128/labels/train2017/000000000486.txt  \n",
            "  inflating: coco128/labels/train2017/000000000109.txt  \n",
            "  inflating: coco128/labels/train2017/000000000294.txt  \n",
            "  inflating: coco128/labels/train2017/000000000257.txt  \n",
            "  inflating: coco128/labels/train2017/000000000531.txt  \n",
            "  inflating: coco128/labels/train2017/000000000247.txt  \n",
            "  inflating: coco128/labels/train2017/000000000086.txt  \n",
            "  inflating: coco128/labels/train2017/000000000092.txt  \n",
            "  inflating: coco128/labels/train2017/000000000643.txt  \n",
            "  inflating: coco128/labels/train2017/000000000326.txt  \n",
            "  inflating: coco128/labels/train2017/000000000332.txt  \n",
            "  inflating: coco128/labels/train2017/000000000078.txt  \n",
            " extracting: coco128/labels/train2017/000000000508.txt  \n",
            "  inflating: coco128/labels/train2017/000000000520.txt  \n",
            " extracting: coco128/labels/train2017/000000000250.txt  \n",
            "  inflating: coco128/labels/train2017/000000000536.txt  \n",
            "  inflating: coco128/labels/train2017/000000000443.txt  \n",
            "  inflating: coco128/labels/train2017/000000000133.txt  \n",
            "  inflating: coco128/labels/train2017/000000000641.txt  \n",
            "  inflating: coco128/labels/train2017/000000000127.txt  \n",
            "  inflating: coco128/README.txt      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "b4hTenv2Sa59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c58ce4b9-444d-49a4-bf22-66992ce7f8e8"
      },
      "source": [
        "!wget -O /content/data/coco128/coco128_renew.yaml https://raw.githubusercontent.com/chulminkw/DLCV/master/data/util/coco128_renew.yaml\n",
        "!cat /content/data/coco128/coco128_renew.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-31 07:31:41--  https://raw.githubusercontent.com/chulminkw/DLCV/master/data/util/coco128_renew.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1594 (1.6K) [text/plain]\n",
            "Saving to: ‘/content/data/coco128/coco128_renew.yaml’\n",
            "\n",
            "\r          /content/   0%[                    ]       0  --.-KB/s               \r/content/data/coco1 100%[===================>]   1.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-31 07:31:41 (13.0 MB/s) - ‘/content/data/coco128/coco128_renew.yaml’ saved [1594/1594]\n",
            "\n",
            "# COCO 2017 dataset http://cocodataset.org - first 128 training images\n",
            "# Train command: python train.py --data coco128.yaml\n",
            "# Default dataset location is next to YOLOv3:\n",
            "#   /parent_folder\n",
            "#     /coco128\n",
            "#     /yolov3\n",
            "\n",
            "\n",
            "# download command/URL (optional)\n",
            "#download: https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip\n",
            "\n",
            "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
            "train: /content/data/coco128/images/train2017/  # 128 images\n",
            "val: /content/data/coco128/images/train2017/  # 128 images\n",
            "\n",
            "# number of classes\n",
            "nc: 80\n",
            "\n",
            "# class names\n",
            "names: [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
            "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
            "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
            "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
            "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
            "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
            "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
            "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
            "         'hair drier', 'toothbrush' ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZkk2f09xWDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb54142-15dc-4b0e-a9d1-899dc02690e5"
      },
      "source": [
        "!cd /content/yolov3; python train.py --img 640 --batch 8 --epochs 3 --data /content/data/coco128/coco128_renew.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.5.0-13-g1be3170 torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=8, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='/content/data/coco128/coco128_renew.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp5', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=8, upload_dataset=False, weights='yolov3.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv3 logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.4 GFLOPS\n",
            "\n",
            "Transferred 440/440 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 75 .bias, 75 conv.weight, 72 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/data/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 272.30it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/data/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 165.76it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.26, Best Possible Recall (BPR) = 0.9946\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp5\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/2     7.31G   0.02774   0.02394  0.007242   0.05893       111       640:   0% 0/16 [00:11<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:730: UserWarning: The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\n",
            "  \"The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\"\n",
            "       0/2     9.67G   0.02976   0.02503  0.008362   0.06316        68       640: 100% 16/16 [01:02<00:00,  3.89s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:27<00:00,  3.48s/it]\n",
            "                 all         128         929       0.812       0.655       0.788       0.541\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/2     9.51G   0.03084   0.02501  0.008129   0.06398        86       640: 100% 16/16 [00:33<00:00,  2.07s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:07<00:00,  1.02it/s]\n",
            "                 all         128         929       0.793       0.667       0.788       0.541\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/2     9.51G   0.02896   0.02226   0.01129    0.0625       121       640: 100% 16/16 [00:33<00:00,  2.08s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:08<00:00,  1.12s/it]\n",
            "                 all         128         929       0.805       0.673       0.796       0.541\n",
            "3 epochs completed in 0.051 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp5/weights/last.pt, 124.2MB\n",
            "Optimizer stripped from runs/train/exp5/weights/best.pt, 124.2MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMrSquxNMDre"
      },
      "source": [
        "### labels 디렉토리명을 변경하고 수행. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r047cg90Sa6P"
      },
      "source": [
        "# labels가 있는 폴더는 반드시 폴더명을 labels로 지정해줘야 함!! \n",
        "!mv /content/data/coco128/labels /content/data/coco128/labels_chg "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef12IcJkLtBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0cb1445-dd47-473f-f08e-e38765d0ee85"
      },
      "source": [
        "!cd /content/yolov3; python train.py --img 640 --batch 8 --epochs 3 --data /content/data/coco128/coco128_renew.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.5.0-13-g1be3170 torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=8, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='/content/data/coco128/coco128_renew.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp6', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=8, upload_dataset=False, weights='yolov3.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv3 logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.4 GFLOPS\n",
            "\n",
            "Transferred 440/440 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 75 .bias, 75 conv.weight, 72 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/data/coco128/labels/train2017' images and labels... 0 found, 128 missing, 0 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 4777.88it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: No labels found in /content/data/coco128/labels/train2017.cache. See https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Cache directory /content/data/coco128/labels is not writeable: [Errno 2] No such file or directory: '/content/data/coco128/labels/train2017.cache'\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 541, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"train.py\", line 192, in train\n",
            "    image_weights=opt.image_weights, quad=opt.quad, prefix=colorstr('train: '))\n",
            "  File \"/content/yolov3/utils/datasets.py\", line 76, in create_dataloader\n",
            "    prefix=prefix)\n",
            "  File \"/content/yolov3/utils/datasets.py\", line 400, in __init__\n",
            "    assert nf > 0 or not augment, f'{prefix}No labels in {cache_path}. Can not train without labels. See {help_url}'\n",
            "AssertionError: \u001b[34m\u001b[1mtrain: \u001b[0mNo labels in /content/data/coco128/labels/train2017.cache. Can not train without labels. See https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLkIb95lL_Tz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42cedb9d-9d5c-473d-e99a-71b181c72e80"
      },
      "source": [
        "# 다시 원복후 학습\n",
        "!mv /content/data/coco128/labels_chg /content/data/coco128/labels \n",
        "!cd /content/yolov3; python train.py --img 640 --batch 8 --epochs 3 --data /content/data/coco128/coco128_renew.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 ✅\n",
            "YOLOv3 🚀 v9.5.0-13-g1be3170 torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=8, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='/content/data/coco128/coco128_renew.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp7', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=8, upload_dataset=False, weights='yolov3.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv3 logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.4 GFLOPS\n",
            "\n",
            "Transferred 440/440 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 75 .bias, 75 conv.weight, 72 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/data/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 262.72it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/data/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 165.90it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.26, Best Possible Recall (BPR) = 0.9946\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp7\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "  0% 0/16 [00:10<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 541, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"train.py\", line 311, in train\n",
            "    scaler.scale(loss).backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 255, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 149, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMCIGcG0Mp4c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}