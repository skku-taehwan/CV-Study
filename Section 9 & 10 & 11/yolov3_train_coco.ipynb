{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "yolov3_train_coco.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "38f3ac328813474089bb86dbd6adb029": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_89098cfbdb504058b7e04f8078a0f48f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7d38d5ed5aac40749fe7430427de6835",
              "IPY_MODEL_c2a23f3f95eb49448c7e2a8f563505fc",
              "IPY_MODEL_9f9c63fc2a6e4c49aa4e5da1b177c2b1"
            ]
          }
        },
        "89098cfbdb504058b7e04f8078a0f48f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d38d5ed5aac40749fe7430427de6835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2bf77efcac5040e6b55a67d425cf27e2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3452b0046e014ca9a1d8dd23495e5869"
          }
        },
        "c2a23f3f95eb49448c7e2a8f563505fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c52f61498bd94343a102e06ab40b8d82",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 6984509,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6984509,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_deea9af6b2a648aabb1facf4e7b29ee8"
          }
        },
        "9f9c63fc2a6e4c49aa4e5da1b177c2b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dc9b2df1dfb949e18b72485f44976c72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6.66M/6.66M [00:00&lt;00:00, 15.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3dc8a8b29614f28916f9f6ae360a03c"
          }
        },
        "2bf77efcac5040e6b55a67d425cf27e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3452b0046e014ca9a1d8dd23495e5869": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c52f61498bd94343a102e06ab40b8d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "deea9af6b2a648aabb1facf4e7b29ee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc9b2df1dfb949e18b72485f44976c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3dc8a8b29614f28916f9f6ae360a03c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPvjfCWE2KFj"
      },
      "source": [
        "### Ultralytics Yolo v3 ì„¤ì¹˜"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "I_Ua0GO8Sa5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4904572f-dde1-4038-b655-0e8a19cc78a3"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov3\n",
        "!cd yolov3;pip install -qr requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov3'...\n",
            "remote: Enumerating objects: 9862, done.\u001b[K\n",
            "remote: Total 9862 (delta 0), reused 0 (delta 0), pack-reused 9862\u001b[K\n",
            "Receiving objects: 100% (9862/9862), 9.19 MiB | 20.87 MiB/s, done.\n",
            "Resolving deltas: 100% (6667/6667), done.\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 5.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b1xaZlnSSa53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abd54b3e-5ba3-49f6-e039-966e24b7030b"
      },
      "source": [
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.9.0+cu111 (Tesla K80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wuNsf3fL2kD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "880f90ef-a849-4e19-dc2e-80e496bb46cc"
      },
      "source": [
        "%cd yolov3\n",
        "!python train.py --img 640 --batch 8 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov3\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 âœ…\n",
            "YOLOv3 ðŸš€ v9.5.0-13-g1be3170 torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=8, bbox_interval=-1, bucket='', cache_images=False, cfg='', data='./data/coco128.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=8, upload_dataset=False, weights='yolov3.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv3 logging with 'pip install wandb' (recommended)\n",
            "Downloading https://github.com/ultralytics/yolov3/releases/download/v9.5.0/yolov3.pt to yolov3.pt...\n",
            "100% 118M/118M [00:01<00:00, 92.3MB/s]\n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.4 GFLOPS\n",
            "\n",
            "Transferred 440/440 items from yolov3.pt\n",
            "\n",
            "WARNING: Dataset not found, nonexistent paths: ['/content/coco128/images/train2017']\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip ...\n",
            "100% 6.66M/6.66M [00:00<00:00, 75.1MB/s]\n",
            "Dataset autodownload success\n",
            "\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 75 .bias, 75 conv.weight, 72 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../coco128/labels/train2017' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 605.33it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.26, Best Possible Recall (BPR) = 0.9946\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/2     7.31G   0.02774   0.02394  0.007242   0.05893       111       640:   0% 0/16 [00:10<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:730: UserWarning: The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\n",
            "  \"The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\"\n",
            "       0/2     9.67G   0.02976   0.02503  0.008362   0.06316        68       640: 100% 16/16 [00:59<00:00,  3.71s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:25<00:00,  3.24s/it]\n",
            "                 all         128         929       0.816       0.652       0.788       0.541\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/2     9.51G   0.03084   0.02501  0.008129   0.06398        86       640: 100% 16/16 [00:31<00:00,  1.96s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:07<00:00,  1.08it/s]\n",
            "                 all         128         929       0.796       0.671       0.789       0.541\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/2     9.51G   0.02896   0.02226   0.01129    0.0625       121       640: 100% 16/16 [00:31<00:00,  1.96s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:08<00:00,  1.09s/it]\n",
            "                 all         128         929       0.804       0.674       0.796       0.542\n",
            "3 epochs completed in 0.049 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 124.2MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 124.2MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtQd5TmHMgxE"
      },
      "source": [
        "### wandb(weight and bias) ëª¨ë“ˆì„ ì„¤ì¹˜\n",
        "* ë¨¼ì € Weight and Bias ì›¹ì‚¬ì´íŠ¸ì— ê³„ì • ìƒì„± ë° ì—°ê³„ í›„ train ìž‘ì—…ì´ í•„ìš”í•  ìˆ˜ë„ ìžˆìŒ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKc9lL_oKCPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d916b4-4ead-4a3e-d6dd-fb6d34f6b1e5"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.6-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.7 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180 kB 45.7 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.4.3-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139 kB 46.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=f6341322069f20b63f6653c05a49a16d1814c2c3b2e9d8aee6f68e1d764c8c2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=cdefe53b3351e8fb58cae65d39de5f392020edfcfa1ed2b9146fc92ea6a8be98\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
            "Successfully installed GitPython-3.1.24 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.4.3 shortuuid-1.0.1 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.6 yaspin-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T2Hcsh1R5iB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55ab14ec-cf0b-49e0-b0f6-ab63e6063aab"
      },
      "source": [
        "%cd /content\n",
        "%cd yolov3\n",
        "!python train.py --img 640 --batch 8 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/yolov3\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 âœ…\n",
            "YOLOv3 ðŸš€ v9.5.0-13-g1be3170 torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=8, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='./data/coco128.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp4', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=8, upload_dataset=False, weights='yolov3.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Don't visualize my results'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 21mb73c1.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to `offline` in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.4 GFLOPS\n",
            "\n",
            "Transferred 440/440 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 75 .bias, 75 conv.weight, 72 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 254.79it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 151.22it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.26, Best Possible Recall (BPR) = 0.9946\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp4\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/2     7.31G   0.02774   0.02394  0.007242   0.05893       111       640:   0% 0/16 [00:09<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:730: UserWarning: The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\n",
            "  \"The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\"\n",
            "       0/2     9.67G   0.02976   0.02503  0.008362   0.06316        68       640: 100% 16/16 [00:57<00:00,  3.59s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:26<00:00,  3.36s/it]\n",
            "                 all         128         929       0.814       0.654       0.788       0.541\n",
            "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/2     9.51G   0.03084   0.02501  0.008129   0.06398        86       640: 100% 16/16 [00:31<00:00,  1.95s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:08<00:00,  1.10s/it]\n",
            "                 all         128         929       0.796       0.671        0.79       0.541\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/2     9.51G   0.02896   0.02225   0.01129    0.0625       121       640: 100% 16/16 [00:30<00:00,  1.93s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:10<00:00,  1.27s/it]\n",
            "                 all         128         929       0.805       0.673       0.796       0.545\n",
            "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
            "3 epochs completed in 0.049 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp4/weights/last.pt, 124.2MB\n",
            "Optimizer stripped from runs/train/exp4/weights/best.pt, 124.2MB\n",
            "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 574... (success).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 â–â–ƒâ–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 â–â–â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision â–ˆâ–â–…\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall â–â–‡â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss â–„â–ˆâ–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss â–‚â–â–ˆ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss â–ˆâ–ˆâ–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss â–ˆâ–‚â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss â–ˆâ–„â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss â–ˆâ–ƒâ–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 â–â–ˆâ–„\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 â–â–ˆâ–„\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 â–ˆâ–…â–\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 0.79605\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 0.54536\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision 0.80528\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall 0.67314\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss 0.02896\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss 0.01129\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss 0.02225\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss 0.02852\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss 0.00453\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss 0.01516\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 0.00019\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 0.00019\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 0.09549\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mwandb sync /content/yolov3/wandb/offline-run-20211031_051031-21mb73c1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[0mFind logs at: ./wandb/offline-run-20211031_051031-21mb73c1/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNIrsZHI0_tz"
      },
      "source": [
        "### Dataset Configì™€ Weight íŒŒì¼ì˜ ìƒëŒ€ ê²½ë¡œ, ì ˆëŒ€ ê²½ë¡œ\n",
        "* train.pyì˜ data optionê°’ìœ¼ë¡œ Dataset config yaml íŒŒì¼ì„ ì§€ì •í•  ìˆ˜ ìžˆìœ¼ë©°, íŒŒì¼ëª…ë§Œ ìž…ë ¥í•  ê²½ìš°ëŠ” yolov3/data ë””ë ‰í† ë¦¬ ì•„ëž˜ì—ì„œ í•´ë‹¹ íŒŒì¼ì„ ì°¾ìŒ. ì ˆëŒ€ ê²½ë¡œë¡œ ìž…ë ¥í•  ê²½ìš° í•´ë‹¹ ê²½ë¡œì—ì„œ ì°¾ìŒ. \n",
        "* weights optionì˜ ê²½ìš° íŒŒì¼ëª…ë§Œ ìž…ë ¥í•  ê²½ìš° yolov3 ë””ë ‰í† ë¦¬ì—ì„œ í•´ë‹¹ íŒŒì¼ì„ ì°¾ìŒ. í•´ë‹¹ íŒŒì¼ì´ ì—†ì„ ê²½ìš° ìžë™ìœ¼ë¡œ í•´ë‹¹ íŒŒì¼ì„ https://github.com/ultralytics/yolov3/releases ì—ì„œ Download í•¨. ì ˆëŒ€ ê²½ë¡œë¥¼ ìž…ë ¥í•œ ê²½ìš° í•´ë‹¹ ê²½ë¡œì—ì„œ íŒŒì¼ì„ ì°¾ë˜ íŒŒì¼ì´ ì—†ìœ¼ë©´ í•´ë‹¹ ê²½ë¡œë¡œ ìžë™ Downloadí•¨. \n",
        "* weights íŒŒì¼ì€ yolov3.pt, yolov3-tiny.pt, yolov3-spp.pt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLfxF4g_3Zh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8314a2-bb58-4a8d-dc15-19a543ee247d"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wPnWKNXMSa5_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63ec5cc6-f63d-4990-8a2a-f68e11a83ef5"
      },
      "source": [
        "!cd yolov3; python train.py --img 640 --batch 8 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave --cache\n",
        "#!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights '' --cfg yolov3.yaml --nosave --cache # weightê°€ ê³µëž€ì´ë©´ ë°˜ë“œì‹œ cfg ë¼ê³  ì¨ì£¼ì–´ì•¼ í•¨!!\n",
        "#!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3-tiny.pt --nosave --cache\n",
        "#!cd yolov3;python train.py --img 640 --batch 16 --epochs 3 --data /content/coco128/coco128.yaml --weights /content/coco128/yolov3-tiny.pt --nosave --cache\n",
        "#!cd yolov3;python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3-spp.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 âœ…\n",
            "YOLOv3 ðŸš€ v9.5.0-13-g1be3170 torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=8, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='./data/coco128.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=8, upload_dataset=False, weights='yolov3.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv3 logging with 'pip install wandb' (recommended)\n",
            "Downloading https://github.com/ultralytics/yolov3/releases/download/v9.5.0/yolov3.pt to yolov3.pt...\n",
            "100% 118M/118M [00:01<00:00, 103MB/s] \n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.4 GFLOPS\n",
            "\n",
            "Transferred 440/440 items from yolov3.pt\n",
            "\n",
            "WARNING: Dataset not found, nonexistent paths: ['/content/coco128/images/train2017']\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip ...\n",
            "100% 6.66M/6.66M [00:00<00:00, 65.7MB/s]\n",
            "Dataset autodownload success\n",
            "\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 75 .bias, 75 conv.weight, 72 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../coco128/labels/train2017' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 672.83it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 252.71it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 166.42it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.26, Best Possible Recall (BPR) = 0.9946\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/2     7.31G   0.02774   0.02394  0.007242   0.05893       111       640:   0% 0/16 [00:11<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:730: UserWarning: The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\n",
            "  \"The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\"\n",
            "       0/2     9.67G   0.02976   0.02503  0.008362   0.06316        68       640: 100% 16/16 [01:02<00:00,  3.89s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:28<00:00,  3.51s/it]\n",
            "                 all         128         929       0.802       0.662       0.787       0.542\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/2     9.51G   0.03084   0.02501   0.00813   0.06398        86       640: 100% 16/16 [00:33<00:00,  2.08s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:07<00:00,  1.02it/s]\n",
            "                 all         128         929       0.797       0.672        0.79       0.541\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/2     9.51G   0.02896   0.02226   0.01129    0.0625       121       640: 100% 16/16 [00:33<00:00,  2.07s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:09<00:00,  1.15s/it]\n",
            "                 all         128         929       0.805       0.673       0.796       0.541\n",
            "3 epochs completed in 0.051 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 124.2MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aumMX7EOnbi",
        "outputId": "8de6c306-f0e3-4f4a-ff2f-4b5b2dd1ee78"
      },
      "source": [
        "#!cd yolov3; python train.py --img 640 --batch 8 --epochs 3 --data coco128.yaml --weights yolov3.pt --nosave --cache\n",
        "#!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights '' --cfg yolov3.yaml --nosave --cache # weightê°€ ê³µëž€ì´ë©´ ë°˜ë“œì‹œ cfg ë¼ê³  ì¨ì£¼ì–´ì•¼ í•¨!!\n",
        "!cd yolov3; python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3-tiny.pt --nosave --cache\n",
        "#!cd yolov3;python train.py --img 640 --batch 16 --epochs 3 --data /content/coco128/coco128.yaml --weights /content/coco128/yolov3-tiny.pt --nosave --cache\n",
        "#!cd yolov3;python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov3-spp.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 âœ…\n",
            "YOLOv3 ðŸš€ v9.5.0-13-g1be3170 torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='./data/coco128.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp2', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, weights='yolov3-tiny.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv3 logging with 'pip install wandb' (recommended)\n",
            "Downloading https://github.com/ultralytics/yolov3/releases/download/v9.5.0/yolov3-tiny.pt to yolov3-tiny.pt...\n",
            "100% 16.9M/16.9M [00:00<00:00, 101MB/s] \n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       464  models.common.Conv                      [3, 16, 3, 1]                 \n",
            "  1                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  2                -1  1      4672  models.common.Conv                      [16, 32, 3, 1]                \n",
            "  3                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  4                -1  1     18560  models.common.Conv                      [32, 64, 3, 1]                \n",
            "  5                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  6                -1  1     73984  models.common.Conv                      [64, 128, 3, 1]               \n",
            "  7                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  8                -1  1    295424  models.common.Conv                      [128, 256, 3, 1]              \n",
            "  9                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            " 10                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.padding.ZeroPad2d      [[0, 1, 0, 1]]                \n",
            " 12                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 1, 0]                     \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 15                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 16                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1    885248  models.common.Conv                      [384, 256, 3, 1]              \n",
            " 20          [19, 15]  1    196350  models.yolo.Detect                      [80, [[10, 14, 23, 27, 37, 58], [81, 82, 135, 169, 344, 319]], [256, 512]]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Model Summary: 59 layers, 8852366 parameters, 8852366 gradients, 13.3 GFLOPS\n",
            "\n",
            "Transferred 72/72 items from yolov3-tiny.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 13 .bias, 13 conv.weight, 11 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 264.67it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 198.72it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.85, Best Possible Recall (BPR) = 0.9903\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp2\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/2     2.75G   0.05195   0.07895   0.02406     0.155       184       640:   0% 0/8 [00:07<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:730: UserWarning: The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\n",
            "  \"The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\"\n",
            "       0/2     7.33G   0.05314    0.0958   0.02647    0.1754       199       640: 100% 8/8 [00:14<00:00,  1.85s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:15<00:00,  3.87s/it]\n",
            "                 all         128         929       0.551       0.358       0.427        0.22\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/2     6.32G   0.05206   0.08904   0.02672    0.1678       130       640: 100% 8/8 [00:03<00:00,  2.43it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:01<00:00,  2.20it/s]\n",
            "                 all         128         929       0.552        0.36       0.425       0.223\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/2     6.32G   0.05491   0.09181   0.02641    0.1731       163       640: 100% 8/8 [00:03<00:00,  2.46it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.06it/s]\n",
            "                 all         128         929       0.565       0.366        0.43       0.225\n",
            "3 epochs completed in 0.014 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp2/weights/last.pt, 17.8MB\n",
            "Optimizer stripped from runs/train/exp2/weights/best.pt, 17.8MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn1UHmyLPAZ5",
        "outputId": "7c10fb1d-7575-4992-ba63-e01eafed09dd"
      },
      "source": [
        "!cd yolov3;python train.py --img 640 --batch 16 --epochs 3 --data /content/coco128/coco128.yaml --weights /content/coco128/yolov3-tiny.pt --nosave --cache\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 âœ…\n",
            "YOLOv3 ðŸš€ v9.5.0-13-g1be3170 torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=16, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='/content/coco128/coco128.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp3', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=16, upload_dataset=False, weights='/content/coco128/yolov3-tiny.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv3 logging with 'pip install wandb' (recommended)\n",
            "Downloading https://github.com/ultralytics/yolov3/releases/download/v9.5.0/yolov3-tiny.pt to /content/coco128/yolov3-tiny.pt...\n",
            "100% 16.9M/16.9M [00:00<00:00, 98.9MB/s]\n",
            "\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       464  models.common.Conv                      [3, 16, 3, 1]                 \n",
            "  1                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  2                -1  1      4672  models.common.Conv                      [16, 32, 3, 1]                \n",
            "  3                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  4                -1  1     18560  models.common.Conv                      [32, 64, 3, 1]                \n",
            "  5                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  6                -1  1     73984  models.common.Conv                      [64, 128, 3, 1]               \n",
            "  7                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            "  8                -1  1    295424  models.common.Conv                      [128, 256, 3, 1]              \n",
            "  9                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 2, 0]                     \n",
            " 10                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.padding.ZeroPad2d      [[0, 1, 0, 1]]                \n",
            " 12                -1  1         0  torch.nn.modules.pooling.MaxPool2d      [2, 1, 0]                     \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 15                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 16                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1    885248  models.common.Conv                      [384, 256, 3, 1]              \n",
            " 20          [19, 15]  1    196350  models.yolo.Detect                      [80, [[10, 14, 23, 27, 37, 58], [81, 82, 135, 169, 344, 319]], [256, 512]]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Model Summary: 59 layers, 8852366 parameters, 8852366 gradients, 13.3 GFLOPS\n",
            "\n",
            "Transferred 72/72 items from /content/coco128/yolov3-tiny.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 13 .bias, 13 conv.weight, 11 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 274.63it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 203.68it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 2.85, Best Possible Recall (BPR) = 0.9903\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp3\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/2     2.75G   0.05195   0.07895   0.02406     0.155       184       640:   0% 0/8 [00:07<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:730: UserWarning: The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\n",
            "  \"The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\"\n",
            "       0/2     7.33G   0.05314    0.0958   0.02647    0.1754       199       640: 100% 8/8 [00:14<00:00,  1.83s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:15<00:00,  3.91s/it]\n",
            "                 all         128         929        0.55       0.357       0.427       0.221\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/2     6.32G   0.05206   0.08904   0.02672    0.1678       130       640: 100% 8/8 [00:03<00:00,  2.44it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:01<00:00,  2.21it/s]\n",
            "                 all         128         929       0.552        0.36       0.424       0.223\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/2     6.32G   0.05491   0.09181   0.02641    0.1731       163       640: 100% 8/8 [00:03<00:00,  2.47it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:03<00:00,  1.06it/s]\n",
            "                 all         128         929       0.567       0.365        0.43       0.225\n",
            "3 epochs completed in 0.014 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp3/weights/last.pt, 17.8MB\n",
            "Optimizer stripped from runs/train/exp3/weights/best.pt, 17.8MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZSXORZdEmvc"
      },
      "source": [
        "!cp /content/yolov3/data/coco128.yaml /content/coco128/coco128.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf1hUSV6Myw9"
      },
      "source": [
        "### COCO128 ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ë³€ê²½í›„ í•™ìŠµ ìˆ˜í–‰\n",
        "* /content/data ì•„ëž˜ì— coco128 ë°ì´í„° download í›„ unzip\n",
        "* coco128 ë””ë ‰í† ë¦¬ê°€ ë³€ê²½ë˜ì—ˆìœ¼ë¯€ë¡œ **coco128.yaml ë°ì´í„°ë„ ë³€ê²½ ì ìš©.** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz37RavwxYE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b84daef-e3f9-4d36-a938-033cd74967e1"
      },
      "source": [
        "%cd /content\n",
        "!rm -rf /content/coco128 # coco128 í´ë” ì‚­ì œ"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "guG3eNgXSa56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "38f3ac328813474089bb86dbd6adb029",
            "89098cfbdb504058b7e04f8078a0f48f",
            "7d38d5ed5aac40749fe7430427de6835",
            "c2a23f3f95eb49448c7e2a8f563505fc",
            "9f9c63fc2a6e4c49aa4e5da1b177c2b1",
            "2bf77efcac5040e6b55a67d425cf27e2",
            "3452b0046e014ca9a1d8dd23495e5869",
            "c52f61498bd94343a102e06ab40b8d82",
            "deea9af6b2a648aabb1facf4e7b29ee8",
            "dc9b2df1dfb949e18b72485f44976c72",
            "d3dc8a8b29614f28916f9f6ae360a03c"
          ]
        },
        "outputId": "64919bab-c047-44ca-eeb9-63c33676c5af"
      },
      "source": [
        "# /content ë””ë ‰í† ë¦¬ì— coco128.zipì„ downloadí•˜ê³  tmp.zipìœ¼ë¡œ ì´ë¦„ ë³€ê²½ í›„ ì••ì¶• í•´ì œ. \n",
        "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip', 'tmp.zip')\n",
        "!unzip -q tmp.zip -d ./ && rm tmp.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38f3ac328813474089bb86dbd6adb029",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/6.66M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD-azX0i2m-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d68554-a73c-44a5-fe0d-815dda853e6a"
      },
      "source": [
        "# /content/data ë””ë ‰í† ë¦¬ì— coco128.zipì„ downloadí•˜ê³  ì••ì¶• í•´ì œ\n",
        "!mkdir /content/data\n",
        "!wget -O /content/data/coco128.zip https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip\n",
        "!cd /content/data; unzip coco128.zip "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-31 07:30:44--  https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/264818686/7a208a00-e19d-11eb-94cf-5222600cc665?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211031%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211031T073044Z&X-Amz-Expires=300&X-Amz-Signature=f7b80dd9b0e5c205aa9bd0a8cfa5f488de548d0a2edab49d26c7d06af03db153&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dcoco128.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-10-31 07:30:44--  https://github-releases.githubusercontent.com/264818686/7a208a00-e19d-11eb-94cf-5222600cc665?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211031%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211031T073044Z&X-Amz-Expires=300&X-Amz-Signature=f7b80dd9b0e5c205aa9bd0a8cfa5f488de548d0a2edab49d26c7d06af03db153&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dcoco128.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.109.154, 185.199.111.154, 185.199.108.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.109.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6984509 (6.7M) [application/octet-stream]\n",
            "Saving to: â€˜/content/data/coco128.zipâ€™\n",
            "\n",
            "/content/data/coco1 100%[===================>]   6.66M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2021-10-31 07:30:45 (76.3 MB/s) - â€˜/content/data/coco128.zipâ€™ saved [6984509/6984509]\n",
            "\n",
            "Archive:  coco128.zip\n",
            "   creating: coco128/\n",
            "  inflating: coco128/.DS_Store       \n",
            "  inflating: coco128/LICENSE         \n",
            "   creating: coco128/images/\n",
            "  inflating: coco128/images/.DS_Store  \n",
            "   creating: coco128/images/train2017/\n",
            "  inflating: coco128/images/train2017/000000000612.jpg  \n",
            "  inflating: coco128/images/train2017/000000000404.jpg  \n",
            "  inflating: coco128/images/train2017/000000000438.jpg  \n",
            "  inflating: coco128/images/train2017/000000000389.jpg  \n",
            "  inflating: coco128/images/train2017/000000000564.jpg  \n",
            "  inflating: coco128/images/train2017/000000000149.jpg  \n",
            "  inflating: coco128/images/train2017/000000000605.jpg  \n",
            "  inflating: coco128/images/train2017/000000000349.jpg  \n",
            "  inflating: coco128/images/train2017/000000000201.jpg  \n",
            "  inflating: coco128/images/train2017/000000000599.jpg  \n",
            "  inflating: coco128/images/train2017/000000000572.jpg  \n",
            "  inflating: coco128/images/train2017/000000000360.jpg  \n",
            "  inflating: coco128/images/train2017/000000000370.jpg  \n",
            "  inflating: coco128/images/train2017/000000000562.jpg  \n",
            "  inflating: coco128/images/train2017/000000000589.jpg  \n",
            "  inflating: coco128/images/train2017/.DS_Store  \n",
            "  inflating: coco128/images/train2017/000000000359.jpg  \n",
            "  inflating: coco128/images/train2017/000000000629.jpg  \n",
            "  inflating: coco128/images/train2017/000000000165.jpg  \n",
            "  inflating: coco128/images/train2017/000000000415.jpg  \n",
            "  inflating: coco128/images/train2017/000000000575.jpg  \n",
            "  inflating: coco128/images/train2017/000000000560.jpg  \n",
            "  inflating: coco128/images/train2017/000000000400.jpg  \n",
            "  inflating: coco128/images/train2017/000000000428.jpg  \n",
            "  inflating: coco128/images/train2017/000000000164.jpg  \n",
            "  inflating: coco128/images/train2017/000000000315.jpg  \n",
            "  inflating: coco128/images/train2017/000000000077.jpg  \n",
            "  inflating: coco128/images/train2017/000000000089.jpg  \n",
            "  inflating: coco128/images/train2017/000000000260.jpg  \n",
            "  inflating: coco128/images/train2017/000000000328.jpg  \n",
            "  inflating: coco128/images/train2017/000000000472.jpg  \n",
            "  inflating: coco128/images/train2017/000000000510.jpg  \n",
            "  inflating: coco128/images/train2017/000000000074.jpg  \n",
            "  inflating: coco128/images/train2017/000000000049.jpg  \n",
            "  inflating: coco128/images/train2017/000000000061.jpg  \n",
            "  inflating: coco128/images/train2017/000000000263.jpg  \n",
            "  inflating: coco128/images/train2017/000000000459.jpg  \n",
            "  inflating: coco128/images/train2017/000000000471.jpg  \n",
            "  inflating: coco128/images/train2017/000000000307.jpg  \n",
            "  inflating: coco128/images/train2017/000000000529.jpg  \n",
            "  inflating: coco128/images/train2017/000000000071.jpg  \n",
            "  inflating: coco128/images/train2017/000000000064.jpg  \n",
            "  inflating: coco128/images/train2017/000000000514.jpg  \n",
            "  inflating: coco128/images/train2017/000000000474.jpg  \n",
            "  inflating: coco128/images/train2017/000000000312.jpg  \n",
            "  inflating: coco128/images/train2017/000000000110.jpg  \n",
            "  inflating: coco128/images/train2017/000000000138.jpg  \n",
            "  inflating: coco128/images/train2017/000000000338.jpg  \n",
            "  inflating: coco128/images/train2017/000000000502.jpg  \n",
            "  inflating: coco128/images/train2017/000000000072.jpg  \n",
            "  inflating: coco128/images/train2017/000000000073.jpg  \n",
            "  inflating: coco128/images/train2017/000000000488.jpg  \n",
            "  inflating: coco128/images/train2017/000000000113.jpg  \n",
            "  inflating: coco128/images/train2017/000000000136.jpg  \n",
            "  inflating: coco128/images/train2017/000000000650.jpg  \n",
            "  inflating: coco128/images/train2017/000000000446.jpg  \n",
            "  inflating: coco128/images/train2017/000000000308.jpg  \n",
            "  inflating: coco128/images/train2017/000000000491.jpg  \n",
            "  inflating: coco128/images/train2017/000000000532.jpg  \n",
            "  inflating: coco128/images/train2017/000000000283.jpg  \n",
            "  inflating: coco128/images/train2017/000000000042.jpg  \n",
            "  inflating: coco128/images/train2017/000000000081.jpg  \n",
            "  inflating: coco128/images/train2017/000000000094.jpg  \n",
            "  inflating: coco128/images/train2017/000000000241.jpg  \n",
            "  inflating: coco128/images/train2017/000000000490.jpg  \n",
            "  inflating: coco128/images/train2017/000000000309.jpg  \n",
            "  inflating: coco128/images/train2017/000000000321.jpg  \n",
            "  inflating: coco128/images/train2017/000000000109.jpg  \n",
            "  inflating: coco128/images/train2017/000000000486.jpg  \n",
            "  inflating: coco128/images/train2017/000000000531.jpg  \n",
            "  inflating: coco128/images/train2017/000000000257.jpg  \n",
            "  inflating: coco128/images/train2017/000000000294.jpg  \n",
            "  inflating: coco128/images/train2017/000000000450.jpg  \n",
            "  inflating: coco128/images/train2017/000000000322.jpg  \n",
            "  inflating: coco128/images/train2017/000000000326.jpg  \n",
            "  inflating: coco128/images/train2017/000000000332.jpg  \n",
            "  inflating: coco128/images/train2017/000000000508.jpg  \n",
            "  inflating: coco128/images/train2017/000000000520.jpg  \n",
            "  inflating: coco128/images/train2017/000000000078.jpg  \n",
            "  inflating: coco128/images/train2017/000000000086.jpg  \n",
            "  inflating: coco128/images/train2017/000000000092.jpg  \n",
            "  inflating: coco128/images/train2017/000000000247.jpg  \n",
            "  inflating: coco128/images/train2017/000000000643.jpg  \n",
            "  inflating: coco128/images/train2017/000000000133.jpg  \n",
            "  inflating: coco128/images/train2017/000000000127.jpg  \n",
            "  inflating: coco128/images/train2017/000000000641.jpg  \n",
            "  inflating: coco128/images/train2017/000000000443.jpg  \n",
            "  inflating: coco128/images/train2017/000000000536.jpg  \n",
            "  inflating: coco128/images/train2017/000000000250.jpg  \n",
            "  inflating: coco128/images/train2017/000000000196.jpg  \n",
            "  inflating: coco128/images/train2017/000000000357.jpg  \n",
            "  inflating: coco128/images/train2017/000000000431.jpg  \n",
            "  inflating: coco128/images/train2017/000000000419.jpg  \n",
            "  inflating: coco128/images/train2017/000000000394.jpg  \n",
            "  inflating: coco128/images/train2017/000000000009.jpg  \n",
            "  inflating: coco128/images/train2017/000000000034.jpg  \n",
            "  inflating: coco128/images/train2017/000000000544.jpg  \n",
            "  inflating: coco128/images/train2017/000000000395.jpg  \n",
            "  inflating: coco128/images/train2017/000000000626.jpg  \n",
            "  inflating: coco128/images/train2017/000000000154.jpg  \n",
            "  inflating: coco128/images/train2017/000000000142.jpg  \n",
            "  inflating: coco128/images/train2017/000000000368.jpg  \n",
            "  inflating: coco128/images/train2017/000000000397.jpg  \n",
            "  inflating: coco128/images/train2017/000000000208.jpg  \n",
            "  inflating: coco128/images/train2017/000000000036.jpg  \n",
            "  inflating: coco128/images/train2017/000000000584.jpg  \n",
            "  inflating: coco128/images/train2017/000000000590.jpg  \n",
            "  inflating: coco128/images/train2017/000000000382.jpg  \n",
            "  inflating: coco128/images/train2017/000000000194.jpg  \n",
            "  inflating: coco128/images/train2017/000000000625.jpg  \n",
            "  inflating: coco128/images/train2017/000000000143.jpg  \n",
            "  inflating: coco128/images/train2017/000000000581.jpg  \n",
            "  inflating: coco128/images/train2017/000000000595.jpg  \n",
            "  inflating: coco128/images/train2017/000000000542.jpg  \n",
            "  inflating: coco128/images/train2017/000000000387.jpg  \n",
            "  inflating: coco128/images/train2017/000000000436.jpg  \n",
            "  inflating: coco128/images/train2017/000000000634.jpg  \n",
            "  inflating: coco128/images/train2017/000000000620.jpg  \n",
            "  inflating: coco128/images/train2017/000000000636.jpg  \n",
            "  inflating: coco128/images/train2017/000000000144.jpg  \n",
            "  inflating: coco128/images/train2017/000000000540.jpg  \n",
            "  inflating: coco128/images/train2017/000000000597.jpg  \n",
            "  inflating: coco128/images/train2017/000000000030.jpg  \n",
            "  inflating: coco128/images/train2017/000000000025.jpg  \n",
            "  inflating: coco128/images/train2017/000000000569.jpg  \n",
            "  inflating: coco128/images/train2017/000000000384.jpg  \n",
            "  inflating: coco128/images/train2017/000000000192.jpg  \n",
            "  inflating: coco128/images/train2017/000000000623.jpg  \n",
            "  inflating: coco128/images/train2017/000000000151.jpg  \n",
            "   creating: coco128/labels/\n",
            "  inflating: coco128/labels/.DS_Store  \n",
            "   creating: coco128/labels/train2017/\n",
            "  inflating: coco128/labels/train2017/000000000260.txt  \n",
            "  inflating: coco128/labels/train2017/000000000089.txt  \n",
            "  inflating: coco128/labels/train2017/000000000328.txt  \n",
            "  inflating: coco128/labels/train2017/000000000472.txt  \n",
            "  inflating: coco128/labels/train2017/000000000315.txt  \n",
            "  inflating: coco128/labels/train2017/000000000077.txt  \n",
            "  inflating: coco128/labels/train2017/000000000263.txt  \n",
            "  inflating: coco128/labels/train2017/000000000049.txt  \n",
            "  inflating: coco128/labels/train2017/000000000061.txt  \n",
            "  inflating: coco128/labels/train2017/000000000459.txt  \n",
            "  inflating: coco128/labels/train2017/000000000471.txt  \n",
            "  inflating: coco128/labels/train2017/000000000074.txt  \n",
            "  inflating: coco128/labels/train2017/000000000510.txt  \n",
            "  inflating: coco128/labels/train2017/000000000514.txt  \n",
            "  inflating: coco128/labels/train2017/000000000064.txt  \n",
            "  inflating: coco128/labels/train2017/000000000110.txt  \n",
            "  inflating: coco128/labels/train2017/000000000138.txt  \n",
            "  inflating: coco128/labels/train2017/000000000312.txt  \n",
            "  inflating: coco128/labels/train2017/000000000474.txt  \n",
            "  inflating: coco128/labels/train2017/000000000307.txt  \n",
            "  inflating: coco128/labels/train2017/000000000071.txt  \n",
            "  inflating: coco128/labels/train2017/000000000529.txt  \n",
            "  inflating: coco128/labels/train2017/000000000073.txt  \n",
            "  inflating: coco128/labels/train2017/000000000113.txt  \n",
            "  inflating: coco128/labels/train2017/000000000488.txt  \n",
            "  inflating: coco128/labels/train2017/000000000338.txt  \n",
            "  inflating: coco128/labels/train2017/000000000072.txt  \n",
            "  inflating: coco128/labels/train2017/000000000502.txt  \n",
            "  inflating: coco128/labels/train2017/000000000149.txt  \n",
            "  inflating: coco128/labels/train2017/000000000389.txt  \n",
            "  inflating: coco128/labels/train2017/000000000404.txt  \n",
            "  inflating: coco128/labels/train2017/000000000438.txt  \n",
            "  inflating: coco128/labels/train2017/000000000612.txt  \n",
            "  inflating: coco128/labels/train2017/000000000564.txt  \n",
            "  inflating: coco128/labels/train2017/000000000572.txt  \n",
            "  inflating: coco128/labels/train2017/000000000599.txt  \n",
            "  inflating: coco128/labels/train2017/000000000360.txt  \n",
            "  inflating: coco128/labels/train2017/000000000349.txt  \n",
            "  inflating: coco128/labels/train2017/000000000605.txt  \n",
            "  inflating: coco128/labels/train2017/000000000201.txt  \n",
            "  inflating: coco128/labels/train2017/000000000629.txt  \n",
            "  inflating: coco128/labels/train2017/000000000359.txt  \n",
            "  inflating: coco128/labels/train2017/000000000370.txt  \n",
            "  inflating: coco128/labels/train2017/000000000589.txt  \n",
            "  inflating: coco128/labels/train2017/000000000562.txt  \n",
            "  inflating: coco128/labels/train2017/000000000560.txt  \n",
            "  inflating: coco128/labels/train2017/000000000164.txt  \n",
            "  inflating: coco128/labels/train2017/000000000400.txt  \n",
            "  inflating: coco128/labels/train2017/000000000428.txt  \n",
            "  inflating: coco128/labels/train2017/000000000415.txt  \n",
            "  inflating: coco128/labels/train2017/000000000165.txt  \n",
            "  inflating: coco128/labels/train2017/000000000575.txt  \n",
            "  inflating: coco128/labels/train2017/000000000544.txt  \n",
            "  inflating: coco128/labels/train2017/000000000034.txt  \n",
            "  inflating: coco128/labels/train2017/000000000626.txt  \n",
            "  inflating: coco128/labels/train2017/000000000154.txt  \n",
            "  inflating: coco128/labels/train2017/000000000395.txt  \n",
            "  inflating: coco128/labels/train2017/000000000394.txt  \n",
            "  inflating: coco128/labels/train2017/000000000431.txt  \n",
            "  inflating: coco128/labels/train2017/000000000357.txt  \n",
            "  inflating: coco128/labels/train2017/000000000419.txt  \n",
            "  inflating: coco128/labels/train2017/000000000196.txt  \n",
            "  inflating: coco128/labels/train2017/000000000009.txt  \n",
            "  inflating: coco128/labels/train2017/000000000584.txt  \n",
            "  inflating: coco128/labels/train2017/000000000590.txt  \n",
            "  inflating: coco128/labels/train2017/000000000143.txt  \n",
            "  inflating: coco128/labels/train2017/000000000625.txt  \n",
            "  inflating: coco128/labels/train2017/000000000194.txt  \n",
            "  inflating: coco128/labels/train2017/000000000382.txt  \n",
            "  inflating: coco128/labels/train2017/000000000397.txt  \n",
            "  inflating: coco128/labels/train2017/000000000368.txt  \n",
            "  inflating: coco128/labels/train2017/000000000142.txt  \n",
            "  inflating: coco128/labels/train2017/000000000036.txt  \n",
            "  inflating: coco128/labels/train2017/000000000208.txt  \n",
            "  inflating: coco128/labels/train2017/000000000542.txt  \n",
            "  inflating: coco128/labels/train2017/000000000581.txt  \n",
            "  inflating: coco128/labels/train2017/000000000595.txt  \n",
            "  inflating: coco128/labels/train2017/000000000634.txt  \n",
            "  inflating: coco128/labels/train2017/000000000620.txt  \n",
            "  inflating: coco128/labels/train2017/000000000436.txt  \n",
            "  inflating: coco128/labels/train2017/000000000387.txt  \n",
            "  inflating: coco128/labels/train2017/000000000569.txt  \n",
            "  inflating: coco128/labels/train2017/000000000025.txt  \n",
            "  inflating: coco128/labels/train2017/000000000623.txt  \n",
            "  inflating: coco128/labels/train2017/000000000151.txt  \n",
            "  inflating: coco128/labels/train2017/000000000192.txt  \n",
            "  inflating: coco128/labels/train2017/000000000384.txt  \n",
            "  inflating: coco128/labels/train2017/000000000636.txt  \n",
            "  inflating: coco128/labels/train2017/000000000144.txt  \n",
            "  inflating: coco128/labels/train2017/000000000030.txt  \n",
            "  inflating: coco128/labels/train2017/000000000597.txt  \n",
            "  inflating: coco128/labels/train2017/000000000540.txt  \n",
            "  inflating: coco128/labels/train2017/000000000241.txt  \n",
            "  inflating: coco128/labels/train2017/000000000094.txt  \n",
            "  inflating: coco128/labels/train2017/000000000309.txt  \n",
            "  inflating: coco128/labels/train2017/000000000321.txt  \n",
            "  inflating: coco128/labels/train2017/000000000490.txt  \n",
            "  inflating: coco128/labels/train2017/000000000491.txt  \n",
            "  inflating: coco128/labels/train2017/000000000446.txt  \n",
            "  inflating: coco128/labels/train2017/000000000308.txt  \n",
            "  inflating: coco128/labels/train2017/000000000650.txt  \n",
            "  inflating: coco128/labels/train2017/000000000136.txt  \n",
            "  inflating: coco128/labels/train2017/000000000081.txt  \n",
            "  inflating: coco128/labels/train2017/000000000042.txt  \n",
            "  inflating: coco128/labels/train2017/000000000283.txt  \n",
            "  inflating: coco128/labels/train2017/000000000532.txt  \n",
            "  inflating: coco128/labels/train2017/000000000450.txt  \n",
            "  inflating: coco128/labels/train2017/000000000322.txt  \n",
            "  inflating: coco128/labels/train2017/000000000486.txt  \n",
            "  inflating: coco128/labels/train2017/000000000109.txt  \n",
            "  inflating: coco128/labels/train2017/000000000294.txt  \n",
            "  inflating: coco128/labels/train2017/000000000257.txt  \n",
            "  inflating: coco128/labels/train2017/000000000531.txt  \n",
            "  inflating: coco128/labels/train2017/000000000247.txt  \n",
            "  inflating: coco128/labels/train2017/000000000086.txt  \n",
            "  inflating: coco128/labels/train2017/000000000092.txt  \n",
            "  inflating: coco128/labels/train2017/000000000643.txt  \n",
            "  inflating: coco128/labels/train2017/000000000326.txt  \n",
            "  inflating: coco128/labels/train2017/000000000332.txt  \n",
            "  inflating: coco128/labels/train2017/000000000078.txt  \n",
            " extracting: coco128/labels/train2017/000000000508.txt  \n",
            "  inflating: coco128/labels/train2017/000000000520.txt  \n",
            " extracting: coco128/labels/train2017/000000000250.txt  \n",
            "  inflating: coco128/labels/train2017/000000000536.txt  \n",
            "  inflating: coco128/labels/train2017/000000000443.txt  \n",
            "  inflating: coco128/labels/train2017/000000000133.txt  \n",
            "  inflating: coco128/labels/train2017/000000000641.txt  \n",
            "  inflating: coco128/labels/train2017/000000000127.txt  \n",
            "  inflating: coco128/README.txt      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "b4hTenv2Sa59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c58ce4b9-444d-49a4-bf22-66992ce7f8e8"
      },
      "source": [
        "!wget -O /content/data/coco128/coco128_renew.yaml https://raw.githubusercontent.com/chulminkw/DLCV/master/data/util/coco128_renew.yaml\n",
        "!cat /content/data/coco128/coco128_renew.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-31 07:31:41--  https://raw.githubusercontent.com/chulminkw/DLCV/master/data/util/coco128_renew.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1594 (1.6K) [text/plain]\n",
            "Saving to: â€˜/content/data/coco128/coco128_renew.yamlâ€™\n",
            "\n",
            "\r          /content/   0%[                    ]       0  --.-KB/s               \r/content/data/coco1 100%[===================>]   1.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-31 07:31:41 (13.0 MB/s) - â€˜/content/data/coco128/coco128_renew.yamlâ€™ saved [1594/1594]\n",
            "\n",
            "# COCO 2017 dataset http://cocodataset.org - first 128 training images\n",
            "# Train command: python train.py --data coco128.yaml\n",
            "# Default dataset location is next to YOLOv3:\n",
            "#   /parent_folder\n",
            "#     /coco128\n",
            "#     /yolov3\n",
            "\n",
            "\n",
            "# download command/URL (optional)\n",
            "#download: https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip\n",
            "\n",
            "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
            "train: /content/data/coco128/images/train2017/  # 128 images\n",
            "val: /content/data/coco128/images/train2017/  # 128 images\n",
            "\n",
            "# number of classes\n",
            "nc: 80\n",
            "\n",
            "# class names\n",
            "names: [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
            "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
            "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
            "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
            "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
            "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
            "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
            "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
            "         'hair drier', 'toothbrush' ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZkk2f09xWDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb54142-15dc-4b0e-a9d1-899dc02690e5"
      },
      "source": [
        "!cd /content/yolov3; python train.py --img 640 --batch 8 --epochs 3 --data /content/data/coco128/coco128_renew.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 âœ…\n",
            "YOLOv3 ðŸš€ v9.5.0-13-g1be3170 torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=8, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='/content/data/coco128/coco128_renew.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp5', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=8, upload_dataset=False, weights='yolov3.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv3 logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.4 GFLOPS\n",
            "\n",
            "Transferred 440/440 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 75 .bias, 75 conv.weight, 72 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/data/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 272.30it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/data/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 165.76it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.26, Best Possible Recall (BPR) = 0.9946\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp5\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/2     7.31G   0.02774   0.02394  0.007242   0.05893       111       640:   0% 0/16 [00:11<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/jit/_trace.py:730: UserWarning: The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\n",
            "  \"The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.\"\n",
            "       0/2     9.67G   0.02976   0.02503  0.008362   0.06316        68       640: 100% 16/16 [01:02<00:00,  3.89s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:27<00:00,  3.48s/it]\n",
            "                 all         128         929       0.812       0.655       0.788       0.541\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       1/2     9.51G   0.03084   0.02501  0.008129   0.06398        86       640: 100% 16/16 [00:33<00:00,  2.07s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:07<00:00,  1.02it/s]\n",
            "                 all         128         929       0.793       0.667       0.788       0.541\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       2/2     9.51G   0.02896   0.02226   0.01129    0.0625       121       640: 100% 16/16 [00:33<00:00,  2.08s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 8/8 [00:08<00:00,  1.12s/it]\n",
            "                 all         128         929       0.805       0.673       0.796       0.541\n",
            "3 epochs completed in 0.051 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp5/weights/last.pt, 124.2MB\n",
            "Optimizer stripped from runs/train/exp5/weights/best.pt, 124.2MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMrSquxNMDre"
      },
      "source": [
        "### labels ë””ë ‰í† ë¦¬ëª…ì„ ë³€ê²½í•˜ê³  ìˆ˜í–‰. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r047cg90Sa6P"
      },
      "source": [
        "# labelsê°€ ìžˆëŠ” í´ë”ëŠ” ë°˜ë“œì‹œ í´ë”ëª…ì„ labelsë¡œ ì§€ì •í•´ì¤˜ì•¼ í•¨!! \n",
        "!mv /content/data/coco128/labels /content/data/coco128/labels_chg "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef12IcJkLtBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0cb1445-dd47-473f-f08e-e38765d0ee85"
      },
      "source": [
        "!cd /content/yolov3; python train.py --img 640 --batch 8 --epochs 3 --data /content/data/coco128/coco128_renew.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 âœ…\n",
            "YOLOv3 ðŸš€ v9.5.0-13-g1be3170 torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=8, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='/content/data/coco128/coco128_renew.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp6', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=8, upload_dataset=False, weights='yolov3.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv3 logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.4 GFLOPS\n",
            "\n",
            "Transferred 440/440 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 75 .bias, 75 conv.weight, 72 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/data/coco128/labels/train2017' images and labels... 0 found, 128 missing, 0 empty, 0 corrupted: 100% 128/128 [00:00<00:00, 4777.88it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: No labels found in /content/data/coco128/labels/train2017.cache. See https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: Cache directory /content/data/coco128/labels is not writeable: [Errno 2] No such file or directory: '/content/data/coco128/labels/train2017.cache'\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 541, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"train.py\", line 192, in train\n",
            "    image_weights=opt.image_weights, quad=opt.quad, prefix=colorstr('train: '))\n",
            "  File \"/content/yolov3/utils/datasets.py\", line 76, in create_dataloader\n",
            "    prefix=prefix)\n",
            "  File \"/content/yolov3/utils/datasets.py\", line 400, in __init__\n",
            "    assert nf > 0 or not augment, f'{prefix}No labels in {cache_path}. Can not train without labels. See {help_url}'\n",
            "AssertionError: \u001b[34m\u001b[1mtrain: \u001b[0mNo labels in /content/data/coco128/labels/train2017.cache. Can not train without labels. See https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLkIb95lL_Tz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42cedb9d-9d5c-473d-e99a-71b181c72e80"
      },
      "source": [
        "# ë‹¤ì‹œ ì›ë³µí›„ í•™ìŠµ\n",
        "!mv /content/data/coco128/labels_chg /content/data/coco128/labels \n",
        "!cd /content/yolov3; python train.py --img 640 --batch 8 --epochs 3 --data /content/data/coco128/coco128_renew.yaml --weights yolov3.pt --nosave --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov3 âœ…\n",
            "YOLOv3 ðŸš€ v9.5.0-13-g1be3170 torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=8, bbox_interval=-1, bucket='', cache_images=True, cfg='', data='/content/data/coco128/coco128_renew.yaml', device='', entity=None, epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=True, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp7', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=8, upload_dataset=False, weights='yolov3.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv3 logging with 'pip install wandb' (recommended)\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
            "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
            " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
            " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
            " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
            " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
            " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
            " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
            " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
            " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
            " 28      [27, 22, 15]  1    457725  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model Summary: 333 layers, 61949149 parameters, 61949149 gradients, 156.4 GFLOPS\n",
            "\n",
            "Transferred 440/440 items from yolov3.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 75 .bias, 75 conv.weight, 72 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/data/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 262.72it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/data/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupted: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB): 100% 128/128 [00:00<00:00, 165.90it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.26, Best Possible Recall (BPR) = 0.9946\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp7\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "  0% 0/16 [00:10<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 541, in <module>\n",
            "    train(hyp, opt, device, tb_writer)\n",
            "  File \"train.py\", line 311, in train\n",
            "    scaler.scale(loss).backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 255, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 149, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMCIGcG0Mp4c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}